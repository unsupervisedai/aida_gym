{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkJG2WR2ystw"
   },
   "source": [
    "# Training AIDA in Google Colab tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKLWYjEj6YQu"
   },
   "source": [
    "In order to train an agent on GPU, go to Runtime->Change runtime type->Hardware accelerator->GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4cD51d-0Qzn"
   },
   "source": [
    "## Import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtsVH1v10doT"
   },
   "source": [
    "Let open the access to **Google Drive** and install/import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19045,
     "status": "ok",
     "timestamp": 1555581820326,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "hBJSZaReyISG",
    "outputId": "13f75f40-dc16-4fff-defd-b1417cbd3b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11161,
     "status": "ok",
     "timestamp": 1555581826854,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "M1e5h8-hXO2s",
    "outputId": "25d8c413-7c66-4f32-8617-049e2044877b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting path.py\n",
      "  Downloading https://files.pythonhosted.org/packages/40/62/1464f08672cac67e529967ba83b46f38da5d0ca48ac1ce2a9e7d7680ea10/path.py-12.0.1-py3-none-any.whl\n",
      "Collecting importlib-metadata>=0.5 (from path.py)\n",
      "  Downloading https://files.pythonhosted.org/packages/58/64/1ce5a6427b9152ef71c14db9e54e74f6f11e8411995bda41979abab817b1/importlib_metadata-0.9-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.3.2 (from importlib-metadata>=0.5->path.py)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/42/10a1f8d29eaf9c7f2b555a5d1d602b9261f2a0cbec08f8f23d9056f5915d/zipp-0.3.3-py2.py3-none-any.whl\n",
      "Installing collected packages: zipp, importlib-metadata, path.py\n",
      "Successfully installed importlib-metadata-0.9 path.py-12.0.1 zipp-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install path.py;\n",
    "from path import Path\n",
    "import math\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48673,
     "status": "ok",
     "timestamp": 1555582093039,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "c1uKAV300qD8",
    "outputId": "473cab19-0c66-4e24-d59f-a70e6318e500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pybullet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/a4/42d502e01f64140666144cbdca9cd909cd03f0e62b4c0d5f76a591e2a1e8/pybullet-2.4.8.tar.gz (39.9MB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39.9MB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pybullet\n",
      "  Building wheel for pybullet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/85/3d/c6/80e5ee17f58abd5e4d7b8ef9e6c5b101ae8863de15cb989409\n",
      "Successfully built pybullet\n",
      "Installing collected packages: pybullet\n",
      "Successfully installed pybullet-2.4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pybullet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giEs0mDI2n1r"
   },
   "source": [
    "Now we have to upload ***aida_gym*** to **Google Drive**. You may either do it yourself or just run the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3188,
     "status": "ok",
     "timestamp": 1555582113076,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "EW3RTlKn2BuD",
    "outputId": "3f3c6e4d-2c9a-45ee-99c4-863dc8aa8ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/content/gdrive/My Drive/aida_gym' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/unsupervisedai/aida_gym /content/gdrive/My\\ Drive/aida_gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m98JFOju4a6y"
   },
   "source": [
    "Now you should see  ***aida_gym*** in the output of the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfOixAko3p_Q"
   },
   "outputs": [],
   "source": [
    "!cd /content/gdrive/My\\ Drive/; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNKZM1ayXImu"
   },
   "outputs": [],
   "source": [
    "sys.path.append('/content/gdrive/My Drive/aida_gym') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SR4uuCE4x6L"
   },
   "source": [
    "And we are able to import packages from ***aida_gym***. If it doesn't work, go to ***github*** and upload another version of ***aida_gym_env.py***. Then wait for several minutes and try to import again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dki9HEUN0vQb"
   },
   "outputs": [],
   "source": [
    "import aida_env.aida_gym_env as e\n",
    "import pybullet as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGZ8Pv5m0GXX"
   },
   "source": [
    "## Soft Actor-Critic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeW64NUnTkzG"
   },
   "outputs": [],
   "source": [
    "def create_log_gaussian(mean, log_std, t):\n",
    "    quadratic = -((0.5 * (t - mean) / (log_std.exp())).pow(2))\n",
    "    l = mean.shape\n",
    "    log_z = log_std\n",
    "    z = l[-1] * math.log(2 * math.pi)\n",
    "    log_p = quadratic.sum(dim=-1) - log_z.sum(dim=-1) - 0.5 * z\n",
    "    return log_p\n",
    "\n",
    "def logsumexp(inputs, dim=None, keepdim=False):\n",
    "    if dim is None:\n",
    "        inputs = inputs.view(-1)\n",
    "        dim = 0\n",
    "    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n",
    "    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n",
    "    if not keepdim:\n",
    "        outputs = outputs.squeeze(dim)\n",
    "    return outputs\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3uUl32wTtdb"
   },
   "outputs": [],
   "source": [
    "LOG_SIG_MAX = 2\n",
    "LOG_SIG_MIN = -20\n",
    "epsilon = 1e-6\n",
    "\n",
    "# Initialize Policy weights\n",
    "def weights_init_(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_dim):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        # Q1 architecture\n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Q2 architecture\n",
    "        self.linear4 = nn.Linear(num_inputs + num_actions, hidden_dim)\n",
    "        self.linear5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear6 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        xu = torch.cat([state, action], 1)\n",
    "        \n",
    "        x1 = F.relu(self.linear1(xu))\n",
    "        x1 = F.relu(self.linear2(x1))\n",
    "        x1 = self.linear3(x1)\n",
    "\n",
    "        x2 = F.relu(self.linear4(xu))\n",
    "        x2 = F.relu(self.linear5(x2))\n",
    "        x2 = self.linear6(x2)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim):\n",
    "        super(GaussianPolicy, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mean_linear = nn.Linear(hidden_dim, num_actions)\n",
    "        self.log_std_linear = nn.Linear(hidden_dim, num_actions)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mean = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, min=LOG_SIG_MIN, max=LOG_SIG_MAX)\n",
    "        return mean, log_std\n",
    "\n",
    "    def sample(self, state):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        normal = Normal(mean, std)\n",
    "        x_t = normal.rsample()  # for reparameterization trick (mean + std * N(0,1))\n",
    "        action = torch.tanh(x_t)\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        # Enforcing Action Bound\n",
    "        log_prob -= torch.log(1 - action.pow(2) + epsilon)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "        return action, log_prob, torch.tanh(mean)\n",
    "\n",
    "class DeterministicPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim):\n",
    "        super(DeterministicPolicy, self).__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mean = nn.Linear(hidden_dim, num_actions)\n",
    "        self.noise = torch.Tensor(num_actions)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mean = torch.tanh(self.mean(x))\n",
    "        return mean\n",
    "\n",
    "\n",
    "    def sample(self, state):\n",
    "        mean = self.forward(state)\n",
    "        noise = self.noise.normal_(0., std=0.1)\n",
    "        noise = noise.clamp(-0.25, 0.25)\n",
    "        action = mean + noise\n",
    "        return action, mean, torch.tensor(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WdQIv3YsO_N"
   },
   "outputs": [],
   "source": [
    "class SAC(object):\n",
    "    def __init__(self, num_inputs, action_space, args):\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "        self.action_space = action_space.shape[0]\n",
    "        self.gamma = args.gamma\n",
    "        self.tau = args.tau\n",
    "\n",
    "        self.policy_type = args.policy\n",
    "        self.target_update_interval = args.target_update_interval\n",
    "        self.automatic_entropy_tuning = args.automatic_entropy_tuning\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if args.cuda else \"cpu\") \n",
    "\n",
    "        self.critic = QNetwork(self.num_inputs, self.action_space, args.hidden_size).to(device=self.device)\n",
    "        self.critic_optim = Adam(self.critic.parameters(), lr=args.lr)\n",
    "\n",
    "        if self.policy_type == \"Gaussian\":\n",
    "            self.alpha = args.alpha\n",
    "            # Target Entropy = ‚àídim(A) (e.g. , -6 for HalfCheetah-v2) as given in the paper\n",
    "            if self.automatic_entropy_tuning == True:\n",
    "                self.target_entropy = -torch.prod(torch.Tensor(action_space.shape).to(self.device)).item()\n",
    "                self.log_alpha = torch.zeros(1, requires_grad=True, device=self.device)\n",
    "                self.alpha_optim = Adam([self.log_alpha], lr=args.lr)\n",
    "\n",
    "\n",
    "            self.policy = GaussianPolicy(self.num_inputs, self.action_space, args.hidden_size).to(self.device)\n",
    "            self.policy_optim = Adam(self.policy.parameters(), lr=args.lr)\n",
    "\n",
    "            self.value = ValueNetwork(self.num_inputs, args.hidden_size).to(self.device)\n",
    "            self.value_target = ValueNetwork(self.num_inputs, args.hidden_size).to(self.device)\n",
    "            self.value_optim = Adam(self.value.parameters(), lr=args.lr)\n",
    "            hard_update(self.value_target, self.value)\n",
    "        else:\n",
    "            self.policy = DeterministicPolicy(self.num_inputs, self.action_space, args.hidden_size).to(self.device)\n",
    "            self.policy_optim = Adam(self.policy.parameters(), lr=args.lr)\n",
    "\n",
    "            self.critic_target = QNetwork(self.num_inputs, self.action_space, args.hidden_size).to(self.device)\n",
    "            hard_update(self.critic_target, self.critic)\n",
    "\n",
    "\n",
    "\n",
    "    def select_action(self, state, eval=False):\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        if eval == False:\n",
    "            self.policy.train()\n",
    "            action, _, _ = self.policy.sample(state)\n",
    "        else:\n",
    "            self.policy.eval()\n",
    "            _, _, action = self.policy.sample(state)\n",
    "        action = action.detach().cpu().numpy()\n",
    "        return action[0]\n",
    "\n",
    "\n",
    "\n",
    "    def update_parameters(self, state_batch, action_batch, reward_batch, next_state_batch, mask_batch, updates):\n",
    "        state_batch = torch.FloatTensor(state_batch).to(self.device)\n",
    "        next_state_batch = torch.FloatTensor(next_state_batch).to(self.device)\n",
    "        action_batch = torch.FloatTensor(action_batch).to(self.device)\n",
    "        reward_batch = torch.FloatTensor(reward_batch).to(self.device).unsqueeze(1)\n",
    "        mask_batch = torch.FloatTensor(mask_batch).to(self.device).unsqueeze(1)\n",
    "\n",
    "        qf1, qf2 = self.critic(state_batch, action_batch) # Two Q-functions to mitigate positive bias in the policy improvement step\n",
    "        pi, log_pi, _ = self.policy.sample(state_batch)\n",
    "\n",
    "        if self.policy_type == \"Gaussian\":\n",
    "            if self.automatic_entropy_tuning:\n",
    "                alpha_loss = -(self.log_alpha * (log_pi + self.target_entropy).detach()).mean()\n",
    "                self.alpha_optim.zero_grad()\n",
    "                alpha_loss.backward()\n",
    "                self.alpha_optim.step()\n",
    "                self.alpha = self.log_alpha.exp()\n",
    "                alpha_logs = torch.tensor(self.alpha) # For TensorboardX logs\n",
    "            else:\n",
    "                alpha_loss = torch.tensor(0.).to(self.device)\n",
    "                alpha_logs = torch.tensor(self.alpha) # For TensorboardX logs\n",
    "\n",
    "            vf = self.value(state_batch) # separate function approximator for the soft value can stabilize training.\n",
    "            with torch.no_grad():\n",
    "                vf_next_target = self.value_target(next_state_batch)\n",
    "                next_q_value = reward_batch + mask_batch * self.gamma * (vf_next_target)\n",
    "        else:\n",
    "            alpha_loss = torch.tensor(0.).to(self.device)\n",
    "            alpha_logs = self.alpha  # For TensorboardX logs\n",
    "            with torch.no_grad():\n",
    "                next_state_action, _, _, _, _, = self.policy.sample(next_state_batch)\n",
    "                # Use a target critic network for deterministic policy and eradicate the value value network completely.\n",
    "                qf1_next_target, qf2_next_target = self.critic_target(next_state_batch, next_state_action)\n",
    "                min_qf_next_target = torch.min(qf1_next_target, qf2_next_target)\n",
    "                next_q_value = reward_batch + mask_batch * self.gamma * (min_qf_next_target)\n",
    "        \n",
    "        \n",
    "        qf1_loss = F.mse_loss(qf1, next_q_value) # JQ = ùîº(st,at)~D[0.5(Q1(st,at) - r(st,at) - Œ≥(ùîºst+1~p[V(st+1)]))^2]\n",
    "        qf2_loss = F.mse_loss(qf2, next_q_value) # JQ = ùîº(st,at)~D[0.5(Q1(st,at) - r(st,at) - Œ≥(ùîºst+1~p[V(st+1)]))^2]\n",
    "        qf1_pi, qf2_pi = self.critic(state_batch, pi)\n",
    "        min_qf_pi = torch.min(qf1_pi, qf2_pi)\n",
    "\n",
    "        if self.policy_type == \"Gaussian\":\n",
    "            vf_target = min_qf_pi - (self.alpha * log_pi)\n",
    "            value_loss = F.mse_loss(vf, vf_target.detach()) # JV = ùîºst~D[0.5(V(st) - (ùîºat~œÄ[Qmin(st,at) - Œ± * log œÄ(at|st)]))^2]\n",
    "\n",
    "        policy_loss = ((self.alpha * log_pi) - min_qf_pi).mean() # JœÄ = ùîºst‚àºD,Œµt‚àºN[Œ± * logœÄ(f(Œµt;st)|st) ‚àí Q(st,f(Œµt;st))]\n",
    "\n",
    "        # Regularization Loss\n",
    "        # mean_loss = 0.001 * mean.pow(2).mean()\n",
    "        # std_loss = 0.001 * log_std.pow(2).mean()\n",
    "\n",
    "        # policy_loss += mean_loss + std_loss\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "        qf1_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "        qf2_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        if self.policy_type == \"Gaussian\":\n",
    "            self.value_optim.zero_grad()\n",
    "            value_loss.backward()\n",
    "            self.value_optim.step()\n",
    "        else:\n",
    "            value_loss = torch.tensor(0.).to(self.device)\n",
    "\n",
    "        self.policy_optim.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.policy_optim.step()\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        We update the target weights to match the current value function weights periodically\n",
    "        Update target parameter after every n(args.target_update_interval) updates\n",
    "        \"\"\"\n",
    "        if updates % self.target_update_interval == 0 and self.policy_type == \"Deterministic\":\n",
    "            soft_update(self.critic_target, self.critic, self.tau)\n",
    "\n",
    "        elif updates % self.target_update_interval == 0 and self.policy_type == \"Gaussian\":\n",
    "            soft_update(self.value_target, self.value, self.tau)\n",
    "        return value_loss.item(), qf1_loss.item(), qf2_loss.item(), policy_loss.item(), alpha_loss.item(), alpha_logs.item()\n",
    "\n",
    "    # Save model parameters\n",
    "    def save_model(self, env_name, suffix=\"\", actor_path=None, critic_path=None, value_path=None):\n",
    "        if not os.path.exists('models/'):\n",
    "            os.makedirs('models/')\n",
    "\n",
    "        if actor_path is None:\n",
    "            actor_path = \"models/sac_actor_{}_{}\".format(env_name, suffix)\n",
    "        if critic_path is None:\n",
    "            critic_path = \"models/sac_critic_{}_{}\".format(env_name, suffix)\n",
    "        if value_path is None:\n",
    "            value_path = \"models/sac_value_{}_{}\".format(env_name, suffix)\n",
    "        print('Saving models to {}, {} and {}'.format(actor_path, critic_path, value_path))\n",
    "        torch.save(self.value.state_dict(), value_path)\n",
    "        torch.save(self.policy.state_dict(), actor_path)\n",
    "        torch.save(self.critic.state_dict(), critic_path)\n",
    "    \n",
    "    # Load model parameters\n",
    "    def load_model(self, actor_path, critic_path, value_path):\n",
    "        print('Loading models from {}, {} and {}'.format(actor_path, critic_path, value_path))\n",
    "        if actor_path is not None:\n",
    "            self.policy.load_state_dict(torch.load(actor_path))\n",
    "        if critic_path is not None:\n",
    "            self.critic.load_state_dict(torch.load(critic_path))\n",
    "        if value_path is not None:\n",
    "            self.value.load_state_dict(torch.load(value_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3_Ukc6rULhL"
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    def save(self, path):\n",
    "        np.save(path/'ReplayMemory_'+str(self.position)+'.npy', memory.buffer)\n",
    "        \n",
    "    def load(self, path, position):\n",
    "        self.buffer = list(np.load(path/'ReplayMemory_'+str(position)+'.npy'))\n",
    "        self.position = position\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Et0Bj18lUf1F"
   },
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "\n",
    "    def action(self, action):\n",
    "        action = (action + 1) / 2  # [-1, 1] => [0, 1]\n",
    "        action *= (self.action_space.high - self.action_space.low)\n",
    "        action += self.action_space.low\n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        action -= self.action_space.low\n",
    "        action /= (self.action_space.high - self.action_space.low)\n",
    "        action = action * 2 - 1\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1555582668128,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "-Cd-lwYr1IYD",
    "outputId": "a3344f09-9488-4123-a538-a5809f1b85ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--cuda'], dest='cuda', nargs=0, const=True, default=False, type=None, choices=None, help='run on CUDA (default: False)', metavar=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "parser.add_argument('--env-name', default=\"HalfCheetah-v2\",\n",
    "                    help='name of the environment to run')\n",
    "parser.add_argument('--policy', default=\"Gaussian\",\n",
    "                    help='algorithm to use: Gaussian | Deterministic')\n",
    "parser.add_argument('--eval', type=bool, default=True,\n",
    "                    help='Evaluates a policy a policy every 10 episode (default:True)')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor for reward (default: 0.99)')\n",
    "parser.add_argument('--tau', type=float, default=0.005, metavar='G',\n",
    "                    help='target smoothing coefficient(œÑ) (default: 0.005)')\n",
    "parser.add_argument('--lr', type=float, default=0.0003, metavar='G',\n",
    "                    help='learning rate (default: 0.0003)')\n",
    "parser.add_argument('--alpha', type=float, default=0.2, metavar='G',\n",
    "                    help='Temperature parameter Œ± determines the relative importance of the entropy term against the reward (default: 0.2)')\n",
    "parser.add_argument('--automatic_entropy_tuning', type=bool, default=False, metavar='G',\n",
    "                    help='Temperature parameter Œ± automaically adjusted.')\n",
    "parser.add_argument('--seed', type=int, default=456, metavar='N',\n",
    "                    help='random seed (default: 456)')\n",
    "parser.add_argument('--batch_size', type=int, default=256, metavar='N',\n",
    "                    help='batch size (default: 256)')\n",
    "parser.add_argument('--num_steps', type=int, default=1000001, metavar='N',\n",
    "                    help='maximum number of steps (default: 1000000)')\n",
    "parser.add_argument('--hidden_size', type=int, default=256, metavar='N',\n",
    "                    help='hidden size (default: 256)')\n",
    "parser.add_argument('--updates_per_step', type=int, default=1, metavar='N',\n",
    "                    help='model updates per simulator step (default: 1)')\n",
    "parser.add_argument('--start_steps', type=int, default=10000, metavar='N',\n",
    "                    help='Steps sampling random actions (default: 10000)')\n",
    "parser.add_argument('--target_update_interval', type=int, default=1, metavar='N',\n",
    "                    help='Value target update per no. of updates per step (default: 1)')\n",
    "parser.add_argument('--replay_size', type=int, default=1000000, metavar='N',\n",
    "                    help='size of replay buffer (default: 10000000)')\n",
    "parser.add_argument('--cuda', action=\"store_true\",\n",
    "                    help='run on CUDA (default: False)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhjLufu50yqG"
   },
   "source": [
    "## Training of an Aida agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UarbcH2Y1hoW"
   },
   "source": [
    "We will pass these arguments to initialize an agent instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYgNH5YgVXZH"
   },
   "outputs": [],
   "source": [
    "global args\n",
    "args = parser.parse_args(args=['--env-name', 'Ant-v2', '--alpha', '0.2', '--cuda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvg1RCNT_FTl"
   },
   "source": [
    "Define the path to save the trained network and the agent's memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkZaoo6p_D02"
   },
   "outputs": [],
   "source": [
    "model_path = Path(root_dir+\"sac_2_saved_models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XT6epJq-9Zoh"
   },
   "source": [
    "Let define our environment. Change weights to modify the reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1555582947701,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "71tEIzD3X-FK",
    "outputId": "be9c8040-ae4f-4e2c-87aa-31a28ad1ddbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urdf_root=/usr/local/lib/python3.6/dist-packages/pybullet_data\n",
      "/content/gdrive/My Drive/aida_gym/aida_env/urdf/plane.urdf\n",
      "/usr/local/lib/python3.6/dist-packages/pybullet_data/plane.urdf\n",
      "0.01 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Could not seed environment <AidaBulletEnv instance>\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = NormalizedActions(e.AidaBulletEnv(\n",
    "               distance_weight=350,\n",
    "               energy_weight=0.5,\n",
    "               shake_weight=40,\n",
    "               drift_weight=40,\n",
    "               height_weight=10,\n",
    "               back_weight=5,\n",
    "               render=False,\n",
    "               on_rack=False))\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "env.seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxNTxZEm-Ds0"
   },
   "source": [
    "Let define our agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vGofFEOYMhF"
   },
   "outputs": [],
   "source": [
    "agent = SAC(env.observation_space.shape[0], env.action_space, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSA6HRfN-MGq"
   },
   "source": [
    "Check that training will be on GPU. The device type should be ***cuda***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1555583040538,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "oCAn0UBXhphx",
    "outputId": "0bdb084f-578d-4b8c-cd4f-13bbf6616cc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyiX_20VYU5_"
   },
   "outputs": [],
   "source": [
    "memory = ReplayMemory(args.replay_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeHNr3tE_6z2"
   },
   "source": [
    "Imports to save videos of the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwU1Me_-ZK8W"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lPGHDCH_3aP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XldAgZOVZRus"
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3dOuKQ8Af8x"
   },
   "source": [
    "If you have a pretrained model, you could load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20804,
     "status": "ok",
     "timestamp": 1555583863849,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "x-fcMUEVOb1H",
    "outputId": "4b1c92ee-6f24-464e-bef7-01f9bd1419eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from /content/gdrive/My Drive/PSC/sac_2_saved_models/sac_actor_aida2_br_, /content/gdrive/My Drive/PSC/sac_2_saved_models/sac_critic_aida2_br_ and /content/gdrive/My Drive/PSC/sac_2_saved_models/sac_value_aida2_br_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = 900007#look on the memory .npy file in your folder to define correctly this position number\n",
    "\n",
    "agent.load_model(actor_path=model_path/\"sac_actor_aida2_br_\",critic_path=model_path/\"sac_critic_aida2_br_\",value_path=model_path/\"sac_value_aida2_br_\")\n",
    "memory.load(model_path, position); len(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCfQs_5NBiou"
   },
   "source": [
    "The most important thing - the training loop!\n",
    "\n",
    "---\n",
    "\n",
    "*   It will save your model to tour **model_path** every 100.000 frames (frames are  different from the episodes) An episode is a period of time when robot walks till he falls. \n",
    "*   It will also save videos of best results to your **model_path**.\n",
    "*   You can see the plot with the reward changing history below the cell.\n",
    "*   Before the training robot will try some random actions for the first ***args.start_steps*** steps (you can change it by commenting the following lines in the loop)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26266,
     "status": "error",
     "timestamp": 1555585080939,
     "user": {
      "displayName": "–ù–∏–∫–∏—Ç–∞ –ö–∞—Ä–∞–µ–≤",
      "photoUrl": "https://lh6.googleusercontent.com/-0miK0wLOYsg/AAAAAAAAAAI/AAAAAAAAAPI/AONwKyC9sJc/s64/photo.jpg",
      "userId": "10603059828424385099"
     },
     "user_tz": -120
    },
    "id": "IBB_Y9x8S6YC",
    "outputId": "5fdb1323-2c03-4ac3-97b9-023d00345512"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAE/CAYAAABFK3gIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwzczq4j/ABRx3p+RJXxGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 29, total numsteps: 2258, reward: 17.68, average reward: -58.81\n",
      "/content/gdrive/My Drive/aida_gym/aida_env/urdf/plane.urdf\n",
      "/usr/local/lib/python3.6/dist-packages/pybullet_data/plane.urdf\n",
      "0.01 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-155f07dc568f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/aida_gym/aida_env/aida_gym_env.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    280\u001b[0m     (_, _, px, _, _) = self._pybullet_client.getCameraImage(\n\u001b[1;32m    281\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRENDER_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRENDER_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviewMatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mview_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         projectionMatrix=proj_matrix, renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mrgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mrgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "rewards = []\n",
    "rews=[]\n",
    "test_rewards = []\n",
    "total_numsteps = 0\n",
    "updates = 0\n",
    "reward_max = 0\n",
    "for i_episode in itertools.count(1):\n",
    "    env.reset();\n",
    "    state,_ , _, _ = env.step(env.action_space.sample())\n",
    "    iteration=0\n",
    "    episode_reward = 0\n",
    "    while True and iteration<14000:\n",
    "        if args.start_steps > total_numsteps:#COMMENT THESE LINES TO NOT DO RANDOM ACTIONS BEFORE THE TRAINING\n",
    "          action = env.action_space.sample() #\n",
    "        else:                                #\n",
    "          action = agent.select_action(state)  # Sample action from policy\n",
    "        if len(memory) > args.batch_size:\n",
    "            for i in range(args.updates_per_step): # Number of updates per step in environment\n",
    "                # Sample a batch from memory\n",
    "                state_batch, action_batch, reward_batch, next_state_batch, mask_batch = memory.sample(args.batch_size)\n",
    "                # Update parameters of all the networks\n",
    "                value_loss, critic_1_loss, critic_2_loss, policy_loss, ent_loss, alpha = agent.update_parameters(state_batch, action_batch,\n",
    "                                                                                                reward_batch, next_state_batch, \n",
    "                                                                                                mask_batch, updates)\n",
    "                updates += 1\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)  # Step\n",
    "        mask = float(not done)  # 1 for not done and 0 for done\n",
    "        \n",
    "       \n",
    "        memory.push(state, action, reward, next_state, mask) # Append transition to memory\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        \n",
    "        if total_numsteps%100000==0:\n",
    "            memory.save(model_path)\n",
    "            agent.save_model(\"aida\",actor_path=model_path/\"sac_actor_aida2_br_\",critic_path=model_path/\"sac_critic_aida2_br_\",value_path=model_path/\"sac_value_aida2_br_\")\n",
    "            print('Model saved')\n",
    "        total_numsteps += 1\n",
    "        episode_reward += reward\n",
    "        iteration+=1\n",
    "        if done:\n",
    "            print('done')\n",
    "            break\n",
    "    \n",
    "    if total_numsteps > args.num_steps:\n",
    "        break\n",
    "   \n",
    "    rewards.append(episode_reward)\n",
    "    plot(total_numsteps, rewards)\n",
    "    print(\"Episode: {}, total numsteps: {}, reward: {}, average reward: {}\".format(i_episode, total_numsteps, np.round(rewards[-1],2),\n",
    "                                                                                np.round(np.mean(rewards[-100:]),2)))\n",
    "    # Save videos of the best results\n",
    "    if episode_reward > reward_max*1.05:\n",
    "        reward_max = episode_reward\n",
    "        env.reset()\n",
    "        state,_ , _, _ = env.step(env.action_space.sample())\n",
    "        episode_reward = 0\n",
    "        i=0\n",
    "        frames=[]\n",
    "\n",
    "        while True and i<1000:\n",
    "            action = agent.select_action(state, eval=True)\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            frames.append(env.render(mode = 'rgb_array'))\n",
    "\n",
    "            state = next_state\n",
    "            i+=1\n",
    "            if done:\n",
    "                break\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.close()\n",
    "        ax.set_xlim(( -4, 4))\n",
    "        ax.set_ylim((-2, 2))\n",
    "        line1, = ax.plot([], [], lw=2)\n",
    "        line2, = ax.plot([], [], lw=2)\n",
    "\n",
    "        # initialization function: plot the background of each frame\n",
    "        patch = plt.imshow(frames[0])\n",
    "        plt.axis('off')\n",
    "\n",
    "        def animate(i):\n",
    "              patch.set_data(frames[i])\n",
    "\n",
    "        anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "\n",
    "        rc('animation', html='jshtml')\n",
    "        Writer = animation.writers['ffmpeg']\n",
    "        writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "        #writer.add_scalar('reward/test', episode_reward, i_episode)\n",
    "        anim.save(model_path/str(i_episode)+'.mp4', writer=writer)\n",
    "        test_rewards.append(episode_reward)\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Test Episode: {}, reward: {}\".format(i_episode, test_rewards[-1]))\n",
    "        print(\"----------------------------------------\")\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBIYb64dFRIw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sac_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
